<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>Institute for Machine Learning @ JKU</title>
<meta name="description" content="Research blog of the Institute for Machine Learning @ JKU.
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->
<link rel="shortcut icon" href="/assets/img/favicon.ico">
<link rel="stylesheet" href="/assets/css/main.css">

<link rel="canonical" href="/">

<!-- Theming-->



  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-KC0VGMCD6W"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());

    gtag('config', 'G-KC0VGMCD6W');
  </script>


    
<!-- MathJax -->
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>


  <body class="fixed-top-nav ">


    <!-- Header -->

    <!-- <div class="container-fluid mx-0 px-0">
  <div class="logo d-flex justify-content-center align-items-center">
    <img class="jku-logo img-fluid rounded" src="/assets/img/jku_ml_1.svg" width=120px height=40px>
    <img class="ellis-logo img-fluid rounded" src="/assets/img/ellis_linz.jpeg" width=250px height=40px>
  </div>
</div> -->


<header>
    <!-- Nav Bar -->

      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <a class="navbar-brand title font-weight-lighter">
         <!-- <span>Institute</span> for Machine  Learning @ JKU -->
         <img class="rounded" src="/assets/img/jku_ml_1.svg" width=100px height=45px>
         <img class="rounded" src="/assets/img/ellis_linz.jpeg" width=200px height=45px>
        </a>
    <div class="container">
      
      <!-- Navbar Toogle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item active">
            <a class="nav-link" href="/">
              about
              
                <span class="sr-only">(current)</span>
              
            </a>
          </li>
          
          <!-- Blog -->
          <li class="nav-item ">
            <a class="nav-link" href="/blog/">
              blog
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
                
                    <div class="dropdown">
                      <a class="nav-link" href="/research/">
                        research
                        
                      </a>
                        <div class="dropdown-content">
                          <a href="/research/deep_learning">Deep Learning</a>
                          <a href="/research/ai_healthcare">AI in Health Care</a>
                          <a href="/research/ai_drug">AI in Drug Discovery</a>
                          <a href="/research/reinforcement_learning">Reinforcement Learning</a>
                          <a href="/research/hopfield_networks">Modern Hopfield Networks</a>
                          <a href="/research/ai4earth">AI 4 Earth</a>
                          <a href="/research/ai4drive">AI 4 Driving</a>
                        </div>
                      </div>
                    
                
          </li>
          
          
          
          
          
          
          
          <li class="nav-item ">
                
                <a class="nav-link" href="/publications/">
                  publications
                  
                </a>
                
          </li>
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
                
                <a class="nav-link" href="/talks/">
                  talks
                  
                </a>
                
          </li>
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="https://www.jku.at/en/institute-for-machine-learning/about-us/team/" target="_blank" rel="noopener noreferrer">
                people
                
              </a>
          </li>
          
          
          
          
          
          <li class="nav-item ">
                
                <a class="nav-link" href="/software/">
                  software
                  
                </a>
                
          </li>
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="https://www.jku.at/en/institute-for-machine-learning/" target="_blank" rel="noopener noreferrer">
                contact
                
              </a>
          </li>
          
          
          
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <article>
    
    <div class="profile float-">
      
        <img class="img-fluid z-depth-1 rounded" src="/assets/img/group_pic_2.jpg">
      
      
    </div>
    

    <div class="clearfix">
      <div class="about-text">
      <p>The Institute for Machine Learning conducts research and provides profound education in machine learning. Its research focuses on development of machine learning and statistical methods. We further apply these methods to various domains like medicine, drug discovery, autonomous driving, earth science, natural language processing, control and others. The institute is led by <a href="https://en.wikipedia.org/wiki/Sepp_Hochreiter">Sepp Hochreiter</a> and is affiliated with Johannes Kepler University Linz and is also one of the founding units of European Lab for Learning and Intelligent Systems (<a href="https://ellis.eu/">ELLIS</a>).</p>

<p>The Institute for Machine Learning is located in the beautiful city of Linz, Austria. Located near the amazing Austrian alps, the once European capital of culture mixes the right balance between nature and urban life. A part of the institute is also located in the city of Vienna, Austria.</p>

    </div>
    </div>
    <div class="row mt-3">
        <div class="col-sm-4 col-xs-6 mt-3 mt-md-0 about-text">
            
              <div class="news">
  <h2>news</h2>
  
    <div class="table-responsive">
      <table class="table table-sm table-borderless">
      
      
        <tr>
          <td>
            <p class="post-meta">Jan 1, 2022</p>
            
              Sepp Hochreiter is on <a href="https://twitter.com/HochreiterSepp" target="_blank"> twitter </a> now!

            
          </td>
        </tr>
      
        <tr>
          <td>
            <p class="post-meta">Jan 11, 2021</p>
            
              Paper accepted at ICLR 2021:
<a href="http://arxiv.org/abs/2008.02217" target="_blank"> Hopfield Networks is all you need </a>

            
          </td>
        </tr>
      
        <tr>
          <td>
            <p class="post-meta">Dec 22, 2020</p>
            
              Talk by Sepp Hochreiter on the topic of Modern Hopfield networks and Dense associative memories:
<a href="https://youtu.be/bsdPZJKOlQs" target="_blank"> link </a>

            
          </td>
        </tr>
      
        <tr>
          <td>
            <p class="post-meta">Nov 25, 2020</p>
            
              New blog post on the relationship of Performers and Hopfield Networks:
<a href="https://ml-jku.github.io/blog-post-performer/" target="_blank"> link </a>

            
          </td>
        </tr>
      
        <tr>
          <td>
            <p class="post-meta">Nov 20, 2020</p>
            
              New blog post on Cross domain few shot learning:
<a href="https://ml-jku.github.io/chef/" target="_blank"> link </a>

            
          </td>
        </tr>
      
      </table>
    </div>
  
</div>

              
        </div>
        <div class="col-sm-8 col-xs-6 mt-3 mt-md-0 about-text">
            
              <div class="publications_about">
  <h2>recent publications</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">JCIM</abbr>
    
  
  </div>

  <div id="seidlImproving2022" class="col-sm-8">
    
      <div class="title">Improving Few- and Zero-Shot Reaction Template Prediction Using Modern Hopfield Networks</div>
      <div class="author">
        
          
            
              
                
                  Seidl, P.,
                
              
            
          
        
          
            
              
                
                  Renz, P.,
                
              
            
          
        
          
            
              
                
                  Dyubankova, N.,
                
              
            
          
        
          
            
              
                
                  Neves, P.,
                
              
            
          
        
          
            
              
                
                  Verhoeven, J.,
                
              
            
          
        
          
            
              
                
                  Wegner, J.,
                
              
            
          
        
          
            
              
                
                  Segler, M.,
                
              
            
          
        
          
            
              
                
                  Hochreiter, S.,
                
              
            
          
        
          
            
              
                
                  and Klambauer, G.
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Journal of Chemical Information and Modeling</em>
      
      
        2022
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://doi.org/10.1021/acs.jcim.1c01065" class="btn btn-sm z-depth-0" role="button" target="_blank">url</a>
    
    
    
    
    
    
      <a href="https://github.com/ml-jku/mhn-react" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Finding synthesis routes for molecules of interest is essential in the discovery of new drugs and materials. To find such routes, computer-assisted synthesis planning (CASP) methods are employed, which rely on a single-step model of chemical reactivity. In this study, we introduce a template-based single-step retrosynthesis model based on Modern Hopfield Networks, which learn an encoding of both molecules and reaction templates in order to predict the relevance of templates for a given molecule. The template representation allows generalization across different reactions and significantly improves the performance of template relevance prediction, especially for templates with few or zero training examples. With inference speed up to orders of magnitude faster than baseline methods, we improve or match the state-of-the-art performance for top-k exact match accuracy for k ≥ 3 in the retrosynthesis benchmark USPTO-50k. Code to reproduce the results is available at github.com/ml-jku/mhn-react.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">ICML</abbr>
    
  
  </div>

  <div id="patil2020alignrudder" class="col-sm-8">
    
      <div class="title">Align-RUDDER: Learning From Few Demonstrations by Reward Redistribution</div>
      <div class="author">
        
          
            
              
                
                  Patil, V.,
                
              
            
          
        
          
            
              
                
                  Hofmarcher, M.,
                
              
            
          
        
          
            
              
                
                  Dinu, M.,
                
              
            
          
        
          
            
              
                
                  Dorfer, M.,
                
              
            
          
        
          
            
              
                
                  Blies, P.,
                
              
            
          
        
          
            
              
                
                  Brandstetter, J.,
                
              
            
          
        
          
            
              
                
                  Arjona-Medina, J.,
                
              
            
          
        
          
            
              
                
                  and Hochreiter, S.
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>arXiv preprint arXiv:2009.14108</em>
      
      
        2022
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://arxiv.org/abs/2009.14108" class="btn btn-sm z-depth-0" role="button" target="_blank">url</a>
    
    
    
    
    
    
      <a href="https://github.com/ml-jku/align-rudder" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Reinforcement Learning algorithms require a large number of samples to solve complex tasks with sparse and delayed rewards. Complex tasks can often be hierarchically decomposed into sub-tasks. A step in the Q-function can be associated with solving a sub-task, where the expectation of the return increases. RUDDER has been introduced to identify these steps and then redistribute reward to them, thus immediately giving reward if sub-tasks are solved. Since the problem of delayed rewards is mitigated, learning is considerably sped up. However, for complex tasks, current exploration strategies as deployed in RUDDER struggle with discovering episodes with high rewards. Therefore, we assume that episodes with high rewards are given as demonstrations and do not have to be discovered by exploration. Typically the number of demonstrations is small and RUDDER’s LSTM model as a deep learning method does not learn well. Hence, we introduce Align-RUDDER, which is RUDDER with two major modifications. First, Align-RUDDER assumes that episodes with high rewards are given as demonstrations, replacing RUDDER’s safe exploration and lessons replay buffer. Second, we replace RUDDER’s LSTM model by a profile model that is obtained from multiple sequence alignment of demonstrations. Profile models can be constructed from as few as two demonstrations as known from bioinformatics. Align-RUDDER inherits the concept of reward redistribution, which considerably reduces the delay of rewards, thus speeding up learning. Align-RUDDER outperforms competitors on complex artificial tasks with delayed reward and few demonstrations. On the MineCraft ObtainDiamond task, Align-RUDDER is able to mine a diamond, though not frequently.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">arXiv</abbr>
    
  
  </div>

  <div id="mayr2021_l3dgfs" class="col-sm-8">
    
      <div class="title">Learning 3D Granular Flow Simulations</div>
      <div class="author">
        
          
            
              
                
                  Mayr, A.,
                
              
            
          
        
          
            
              
                
                  Lehner, S.,
                
              
            
          
        
          
            
              
                
                  Mayrhofer, A.,
                
              
            
          
        
          
            
              
                
                  Kloss, C.,
                
              
            
          
        
          
            
              
                
                  Hochreiter, S.,
                
              
            
          
        
          
            
              
                
                  and Brandstetter, J.
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em></em>
      
      
        2021
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://arxiv.org/abs/2105.01636" class="btn btn-sm z-depth-0" role="button" target="_blank">url</a>
    
    
    
    
    
    
    
      
      <a href="https://simdl.github.io/posters/42-supp_poster.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Poster</a>
      
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Recently, the application of machine learning models has gained momentum in natural sciences and engineering, which is a natural fit due to the abundance of data in these fields. However, the modeling of physical processes from simulation data without first principle solutions remains difficult. Here, we present a Graph Neural Networks approach towards accurate modeling of complex 3D granular flow simulation processes created by the discrete element method LIGGGHTS and concentrate on simulations of physical systems found in real world applications like rotating drums and hoppers. We discuss how to implement Graph Neural Networks that deal with 3D objects, boundary conditions, particle - particle, and particle - boundary interactions such that an accurate modeling of relevant physical quantities is made possible. Finally, we compare the machine learning based trajectories to LIGGGHTS trajectories in terms of particle flows and mixing entropies.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">HESSD</abbr>
    
  
  </div>

  <div id="klotz2021uncertainty" class="col-sm-8">
    
      <div class="title">Uncertainty Estimation with Deep Learning for Rainfall-Runoff Modelling</div>
      <div class="author">
        
          
            
              
                
                  Klotz, D.,
                
              
            
          
        
          
            
              
                
                  Kratzert, F.,
                
              
            
          
        
          
            
              
                
                  Gauch, M.,
                
              
            
          
        
          
            
              
                
                  Keefe Sampson, A.,
                
              
            
          
        
          
            
              
                
                  Brandstetter, J.,
                
              
            
          
        
          
            
              
                
                  Klambauer, G.,
                
              
            
          
        
          
            
              
                
                  Hochreiter, S.,
                
              
            
          
        
          
            
              
                
                  and Nearing, G.
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Hydrology and Earth System Sciences Discussions</em>
      
      
        2021
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://hess.copernicus.org/preprints/hess-2021-154/" class="btn btn-sm z-depth-0" role="button" target="_blank">url</a>
    
    
    
    
    
    
      <a href="https://github.com/neuralhydrology/neuralhydrology" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Deep Learning is becoming an increasingly important way to produce accurate hydrological predictions across a wide range of spatial and temporal scales. Uncertainty estimations are critical for actionable hydrological forecasting, and while standardized community benchmarks are becoming an increasingly important part of hydrological model development and research, similar tools for benchmarking uncertainty estimation are lacking. This contributions demonstrates that accurate uncertainty predictions can be obtained with Deep Learning. We establish an uncertainty estimation benchmarking procedure and present four Deep Learning baselines. Three baselines are based on Mixture Density Networks and one is based on Monte Carlo dropout. The results indicate that these approaches constitute strong baselines, especially the former ones. Additionaly, we provide a post-hoc model analysis to put forward some qualitative understanding of the resulting models. This analysis extends the notion of performance and show that learn nuanced behaviors in different situations.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">QSAR</abbr>
    
  
  </div>

  <div id="seidlBenchmarking2021" class="col-sm-8">
    
      <div class="title">Benchmarking recent Deep Learning methods on the extended Tox21 data set</div>
      <div class="author">
        
          
            
              
                
                  Seidl, P.,
                
              
            
          
        
          
            
              
                
                  Halmich, C.,
                
              
            
          
        
          
            
              
                
                  Mayr, A.,
                
              
            
          
        
          
            
              
                
                  Vall, A.,
                
              
            
          
        
          
            
              
                
                  Ruch, P.,
                
              
            
          
        
          
            
              
                
                  Hochreiter, S.,
                
              
            
          
        
          
            
              
                
                  and Klambauer, G.
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In </em>
      
      
        2021
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://www.ascctox.org/sites/default/files/QSAR%202021%20Program.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">url</a>
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>The Tox21 data set has evolved into a standard benchmark for computational QSAR methods in toxicology. One limitation of the Tox21 data set is, however, that it only contains twelve toxic assays which strongly restricts its power to distinguish the strength of computational methods. We ameliorate this problem by benchmarking on the extended Tox21 dataset with 68 publicly available assays in order to allow for a better assessment and characterization. The broader range of assays also allows for multi-task approaches, which have been particularly successful as predictive models. Furthermore, previous publications comparing methods on Tox21 did not include recent developments in the field of machine learning, such as graph neural and modern Hopfield networks. Thus we benchmark a set of prominent machine learning methods including those new types of neural networks. The results of the benchmarking study show that the best methods are modern Hopfield networks and multi-task graph neural networks with an average area-under-ROCcurve of 0.91 ± 0.05 (standard deviation across assays), while traditional methods, such as Random Forests fall behind by a substantial margin. Our results of the full benchmark suggest that multi-task learning has a stronger effect on the predictive performance than the choice of the representation of the molecules, such as graph, descriptors, or fingerprints.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="widrich2021modern" class="col-sm-8">
    
      <div class="title">Modern Hopfield Networks for Return Decomposition for Delayed Rewards</div>
      <div class="author">
        
          
            
              
                
                  Widrich, M.,
                
              
            
          
        
          
            
              
                
                  Hofmarcher, M.,
                
              
            
          
        
          
            
              
                
                  Patil, V.,
                
              
            
          
        
          
            
              
                
                  Bitto-Nemling, A.,
                
              
            
          
        
          
            
              
                
                  and Hochreiter, S.
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Deep RL Workshop NeurIPS 2021</em>
      
      
        2021
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://openreview.net/forum?id=t0PQSDcqAiy" class="btn btn-sm z-depth-0" role="button" target="_blank">url</a>
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Delayed rewards, which are separated from their causative actions by irrelevant actions, hamper learning in reinforcement learning (RL). Especially real world problems often contain such delayed and sparse rewards. Recently, return decomposition for delayed rewards (RUDDER) employed pattern recognition to remove or reduce delay in rewards, which dramatically simplifies the learning task of the underlying RL method. RUDDER was realized using a long short-term memory (LSTM). The LSTM was trained to identify important state-action pair patterns, responsible for the return. Reward was then redistributed to these important state-action pairs. However, training the LSTM is often difficult and requires a large number of episodes. In this work, we replace the LSTM with the recently proposed continuous modern Hopfield networks (MHN) and introduce Hopfield-RUDDER. MHN are powerful trainable associative memories with large storage capacity. They require only few training samples and excel at identifying and recognizing patterns. We use this property of MHN to identify important state-action pairs that are associated with low or high return episodes and directly redistribute reward to them. However, in partially observable environments, Hopfield-RUDDER requires additional information about the history of state-action pairs. Therefore, we evaluate several methods for compressing history and introduce reset-max history, a lightweight history compression using the max-operator in combination with a reset gate. We experimentally show that Hopfield-RUDDER is able to outperform LSTM-based RUDDER on various 1D environments with small numbers of episodes. Finally, we show in preliminary experiments that Hopfield-RUDDER scales to highly complex environments with the Minecraft ObtainDiamond task from the MineRL NeurIPS challenge.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">HESS</abbr>
    
  
  </div>

  <div id="kratzert2021synergy" class="col-sm-8">
    
      <div class="title">A note on leveraging synergy in multiple meteorological datasets with deep learning for rainfall-runoff modeling</div>
      <div class="author">
        
          
            
              
                
                  Kratzert, F.,
                
              
            
          
        
          
            
              
                
                  Klotz, D.,
                
              
            
          
        
          
            
              
                
                  Hochreiter, S.,
                
              
            
          
        
          
            
              
                
                  and Nearing, G.
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Hydrology and Earth System Sciences</em>
      
      
        2021
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://hess.copernicus.org/preprints/hess-2020-221/" class="btn btn-sm z-depth-0" role="button" target="_blank">url</a>
    
    
    
    
    
    
      <a href="https://github.com/kratzert/multiple_forcing" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>A deep learning rainfall-runoff model can take multiple meteorological forcing products as inputs and learn to combine them in spatially and temporally dynamic ways. This is demonstrated using Long Short Term Memory networks (LSTMs) trained over basins in the continental US using the CAMELS data set. Using multiple precipitation products (NLDAS, Maurer, DayMet) in a single LSTM significantly improved simulation accuracy relative to using only individual precipitation products. A sensitivity analysis showed that the LSTM learned to utilize different precipitation products in different ways in different basins and for simulating different parts of the hydrograph in individual basins.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">HESS</abbr>
    
  
  </div>

  <div id="gauch2021mtslstm" class="col-sm-8">
    
      <div class="title">Rainfall–runoff prediction at multiple timescales with a single Long Short-Term Memory network</div>
      <div class="author">
        
          
            
              
                
                  Gauch, M.,
                
              
            
          
        
          
            
              
                
                  Kratzert, F.,
                
              
            
          
        
          
            
              
                
                  Klotz, D.,
                
              
            
          
        
          
            
              
                
                  Nearing, G.,
                
              
            
          
        
          
            
              
                
                  Lin, J.,
                
              
            
          
        
          
            
              
                
                  and Hochreiter, S.
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Hydrology and Earth System Sciences</em>
      
      
        2021
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://hess.copernicus.org/articles/25/2045/2021/" class="btn btn-sm z-depth-0" role="button" target="_blank">url</a>
    
    
    
    
    
    
      <a href="https://github.com/gauchm/mts-lstm" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Long Short-Term Memory (LSTM) networks have been applied to daily discharge prediction with remarkable success. Many practical applications, however, require predictions at more granular timescales. For instance, accurate prediction of short but extreme flood peaks can make a lifesaving difference, yet such peaks may escape the coarse temporal resolution of daily predictions. Naively training an LSTM on hourly data, however, entails very long input sequences that make learning difficult and computationally expensive. In this study, we propose two multi-timescale LSTM (MTS-LSTM) architectures that jointly predict multiple timescales within one model, as they process long-past inputs at a different temporal resolution than more recent inputs. In a benchmark on 516 basins across the continental United States, these models achieved significantly higher Nash–Sutcliffe efficiency (NSE) values than the US National Water Model. Compared to naive prediction with distinct LSTMs per timescale, the multi-timescale architectures are computationally more efficient with no loss in accuracy. Beyond prediction quality, the multi-timescale LSTM can process different input variables at different timescales, which is especially relevant to operational applications where the lead time of meteorological forcings depends on their temporal resolution.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">Frontiers in AI</abbr>
    
  
  </div>

  <div id="vall_promise_2021" class="col-sm-8">
    
      <div class="title">The Promise of AI for DILI Prediction</div>
      <div class="author">
        
          
            
              
                
                  Vall, A.,
                
              
            
          
        
          
            
              
                
                  Sabnis, Y.,
                
              
            
          
        
          
            
              
                
                  Shi, J.,
                
              
            
          
        
          
            
              
                
                  Class, R.,
                
              
            
          
        
          
            
              
                
                  Hochreiter, S.,
                
              
            
          
        
          
            
              
                
                  and Klambauer, G.
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Frontiers in Artificial Intelligence</em>
      
      
        2021
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://www.frontiersin.org/articles/10.3389/frai.2021.638410" class="btn btn-sm z-depth-0" role="button" target="_blank">url</a>
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Drug-induced liver injury (DILI) is a common reason for the withdrawal of a drug from the market. Early assessment of DILI risk is an essential part of drug development, but it is rendered challenging prior to clinical trials by the complex factors that give rise to liver damage. Artificial intelligence (AI) approaches, particularly those building on machine learning, range from random forests to more recent techniques such as deep learning, and provide tools that can analyze chemical compounds and accurately predict some of their properties based purely on their structure. This article reviews existing AI approaches to predicting DILI and elaborates on the challenges that arise from the as yet limited availability of data. Future directions are discussed focusing on rich data modalities, such as 3D spheroids, and the slow but steady increase in drugs annotated with DILI risk labels.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">medRxiv</abbr>
    
  
  </div>

  <div id="roland2021covid" class="col-sm-8">
    
      <div class="title">Machine Learning based COVID-19 Diagnosis from Blood Tests with Robustness to Domain Shifts</div>
      <div class="author">
        
      </div>

      <div class="periodical">
      
        <em>medRxiv preprint doi:10.1101/2021.04.06.21254997</em>
      
      
        2021
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://www.medrxiv.org/content/10.1101/2021.04.06.21254997v1.full-text" class="btn btn-sm z-depth-0" role="button" target="_blank">url</a>
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>We investigate machine learning models that identify COVID-19 positive patients and estimate the mortality risk based on routinely acquired blood tests in a hospital setting. However, during pandemics or new outbreaks, disease and testing characteristics change, thus we face domain shifts. Domain shifts can be caused, e.g., by changes in the disease prevalence (spreading or tested population), by refined RT-PCR testing procedures (taking samples, laboratory), or by virus mutations. Therefore, machine learning models for diagnosing COVID-19 or other diseases may not be reliable and degrade in performance over time. To countermand this effect, we propose methods that first identify domain shifts and then reverse their negative effects on the model performance. Frequent re-training and reassessment, as well as stronger weighting of more recent samples, keeps model performance and credibility at a high level over time. Our diagnosis models are constructed and tested on large-scale data sets, steadily adapt to observed domain shifts, and maintain high ROC AUC values along pandemics.</p>
    </div>
    
  </div>
</div>
</li></ol>
</div>

              
        </div>
    </div>
    
    <div class="social">
      <span class="contact-icon text-center">
  <a href="mailto:%73%65%63%72%65%74%61%72%79@%6D%6C.%6A%6B%75.%61%74"><i class="fas fa-envelope"></i></a>
  
  
  
  
  <a href="https://github.com/ml-jku" target="_blank" title="GitHub"><i class="fab fa-github"></i></a>
  
  <a href="https://twitter.com/LITAILab" target="_blank" title="Twitter"><i class="fab fa-twitter"></i></a>
  
  
  
  
  
</span>

      <div class="contact-note"></div>
    </div>
    
  </article>

</div>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    &copy; Copyright 2022 Institute for Machine Learning @ JKU.
    Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>.

    
  </div>
</footer>



  </body>

  <!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>

<!-- Load DarkMode JS -->
<script src="/assets/js/dark_mode.js"></script>


</html>
